{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymlneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pyML.VAE import VAE, Beta_VAE\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16000\n",
    "LATENT_DIMS = 50\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    dev = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_channels = 3\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(64),\n",
    "        transforms.Normalize(\n",
    "            [0 for _ in range(no_channels)], [1 for _ in range(no_channels)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder(root='Bitmoji-Faces', transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bitmoji_model(VAE):\n",
    "    def __init__(self, latent_dims, device = None,beta = 1) -> None:\n",
    "        super(bitmoji_model, self).__init__(device=device)\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(576, 128),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.mu_layer = nn.Linear(128, latent_dims)\n",
    "        self.sigma_layer = nn.Linear(128, latent_dims)\n",
    "\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(latent_dims, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 576),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(64, 3, 3)),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 3, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "        self.dev = device\n",
    "        self.beta = beta\n",
    "\n",
    "        self.N = torch.distributions.Normal(0,1)\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = self.enc(x)\n",
    "\n",
    "        mu = self.mu_layer(x)\n",
    "        sigma = torch.exp(self.sigma_layer(x))\n",
    "\n",
    "        return [mu, sigma]\n",
    "\n",
    "    def repametrize(self, params):\n",
    "        self.params = params\n",
    "\n",
    "        mu = params[0]\n",
    "        sigma = params[1]\n",
    "\n",
    "        e = self.N.sample(mu.shape)\n",
    "        \n",
    "        if self.dev:\n",
    "            e = e.to(self.dev)\n",
    "\n",
    "        return mu + sigma*e\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.dec(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def loss_fn(self, x, y):\n",
    "        mu = self.params[0]\n",
    "        sigma = self.params[1]\n",
    "\n",
    "        kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        return ((x - y)**2).sum() + self.beta*kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "vae = bitmoji_model(LATENT_DIMS, device=dev)\n",
    "vae.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(dataloader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100, LATENT_DIMS)\n",
    "z = z.to(dev)\n",
    "img_recon = vae.generate(z)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(\n",
    "    img_recon,\n",
    "    nrow=10,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "trans = transforms.ToPILImage()\n",
    "pil_img = trans(img_grid)\n",
    "\n",
    "plt.imshow(pil_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ADRL': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f09f5b5b51b597f1c6c549016ce33f987109769ac8e4eb3f83f958c2707f7a74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
